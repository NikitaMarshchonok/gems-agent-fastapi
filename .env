# LLM Backend Configuration
LLM_BACKEND=gemini
EMBED_BACKEND=ollama

# Gemini Configuration
GEMINI_API_KEY=AIzaSyCVMbaxfKaO8aN42QQNfdpEQCWfyKXqrA8
GEMINI_MODEL=gemini-2.0-flash
GEMINI_EMBED_MODEL=text-embedding-004

# Ollama Configuration (backup)
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_EMBED_MODEL=nomic-embed-text

# OpenAI Configuration (backup)
OPENAI_API_KEY=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
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBED_MODEL=text-embedding-3-small

# Timeout settings
HTTP_TIMEOUT=120
EMBED_TIMEOUT=120
